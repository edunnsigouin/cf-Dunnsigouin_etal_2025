"""
Calculates the mean-square-error skill score as a function of 
lead time for ecmwf forecasts. Reference forecasts are either 
era5 climatology or era5 persistence. Verification is era5.
"""

import numpy  as np
import xarray as xr
from dask.diagnostics   import ProgressBar
from forsikring import config,misc,s2s
import random

def preprocess(ds):
    '''change time dim from calendar dates to numbers'''
    if ds.time.size == 15:
        ds['time'] = np.arange(1,ds.time.size+1,1) # high resolution lead times
    elif ds.time.size == 31:
        ds['time'] = np.arange(16,47,1) # low resolution lead times
    return ds

# INPUT -----------------------------------------------
ref_forecast_flag = 'clim'                   # clim or pers
variable          = 'tp24'                   # tp24,rn24,mx24rn6,mx24tp6,mx24tpr
mon_thu_start     = ['20210104','20210107']  # first monday & thursday initialization date of forecast
num_i_weeks       = 52                        # number of weeks withe forecasts
grid              = '0.25x0.25'              # '0.25x0.25' & '0.5x0.5'
nshuffle          = 1000                     # number of times to shuffle initialization dates for error bars
nsample           = 50
comp_lev          = 5
write2file        = True
# -----------------------------------------------------      

misc.tic()

# initialize msess array
dim              = s2s.get_dim(grid)
msess            = np.zeros((dim.ntime,nshuffle))
mse_forecast     = np.zeros((dim.ntime,nshuffle))

# get all initialization dates and convert to list
init_dates        = s2s.get_monday_thursday_dates(mon_thu_start,num_i_weeks)
init_dates        = init_dates.strftime('%Y-%m-%d').values.tolist()

# define paths
path_in_forecast     = config.dirs['forecast_daily'] + variable + '/'
path_in_verification = config.dirs['era5_model_daily'] + variable + '/'
path_in_ref_forecast = config.dirs['era5_model_clim'] + variable + '/'
path_out             = config.dirs['calc_forecast_daily'] + variable + '/'

# get list of filenames                                                                                                                                                                
filenames_verification = []
filenames_ref_forecast = []    
filenames_forecast     = []
for j in init_dates:
    filename1 = path_in_forecast + variable + '_' + grid + '_' + j + '.nc'
    filename2 = path_in_verification + variable + '_' + grid + '_' + j + '.nc'
    if ref_forecast_flag == 'clim':
        filename3 = path_in_ref_forecast + variable + '_' + grid + '_' + j + '.nc'
    elif ref_forecast_flag == 'pers':
        print('need to code this!')
    filenames_forecast.append(filename1)
    filenames_verification.append(filename2)
    filenames_ref_forecast.append(filename3)
    
# read in files     
ds_ref_forecast = xr.open_mfdataset(filenames_ref_forecast,preprocess=preprocess,combine='nested',concat_dim='chunks')
ds_verification = xr.open_mfdataset(filenames_verification,preprocess=preprocess,combine='nested',concat_dim='chunks')
ds_forecast     = xr.open_mfdataset(filenames_forecast,preprocess=preprocess,combine='nested',concat_dim='chunks').mean(dim='number') # ensemble mean

# calc squared error for all forecasts individually
error_forecast     = (ds_forecast[variable] - ds_verification[variable])**2
error_ref_forecast = (ds_ref_forecast[variable] - ds_verification[variable])**2

ds_ref_forecast.close()
ds_verification.close()
ds_forecast.close()

# weighted spatial mean
error_forecast     = misc.xy_mean(error_forecast)
error_ref_forecast = misc.xy_mean(error_ref_forecast)

# calculate explicitely
with ProgressBar():
    error_forecast     = error_forecast.compute().to_dataset()
    error_ref_forecast = error_ref_forecast.compute().to_dataset()

# bootstrap
chunks           = np.arange(0,len(init_dates),1)
chunks_random    = chunks.copy()
mse_ref_forecast = (1/chunks.size)*error_ref_forecast[variable].sum(dim='chunks').values
for i in range(nshuffle):

    # calc mean square error    
    mse_forecast[:,i] = (1/chunks_random.size)*error_forecast[variable].sel(chunks=chunks_random).sum(dim='chunks').values 
    
    # calc msess
    msess[:,i] = 1 - mse_forecast[:,i]/mse_ref_forecast[:]
    
    # shuffle forecasts (chunks) randomly with replacement
    chunks_random = np.random.choice(chunks,nsample,replace='True')
       

if write2file:    
    print('writing to file..')
    msess             = xr.DataArray(data=msess,dims=["time","number"],
                                     coords=dict(number=np.arange(0,nshuffle,1),time=dim.time),
                                     attrs=dict(description='mean square error skill score',units='unitless'),
                                     name='msess')
    mse_forecast      = xr.DataArray(data=mse_forecast,dims=["time","number"],
                                     coords=dict(number=np.arange(0,nshuffle,1),time=dim.time),
                                     attrs=dict(description='mean square error of forecast',units='?'),
                                     name='mse_forecast')
    mse_ref_forecast  = xr.DataArray(data=mse_ref_forecast,dims=["time"],
                                     coords=dict(time=dim.time),
                                     attrs=dict(description='mean square error of reference forecast',units='?'),
                                     name='mse_ref_forecast')
    ds                = xr.merge([msess,mse_forecast,mse_ref_forecast])
    filename_out      = 'msess_mse_' + ref_forecast_flag + '_' + grid + '_' + init_dates[0] + '_' + init_dates[-1] + '.nc'
    #s2s.to_netcdf_pack64bit(ds['msess'],path_out + filename_out)
    ds.to_netcdf(path_out+filename_out)
    print('compress file to reduce space..\n')
    s2s.compress_file(comp_lev,3,filename_out,path_out)

misc.toc()

